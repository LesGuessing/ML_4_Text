{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework with Yelp reviews data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This assignment uses a small subset of the data from Kaggle's [Yelp Business Rating Prediction](https://www.kaggle.com/c/yelp-recsys-2013) competition.\n",
    "\n",
    "**Description of the data:**\n",
    "\n",
    "- **`yelp.json`** is the original format of the file. **`yelp.csv`** contains the same data, in a more convenient format. Both of the files are in the course repo (in the **`data`** directory), so there is no need to download the data from the Kaggle website.\n",
    "- Each observation (row) in this dataset is a review of a particular business by a particular user.\n",
    "- The **stars** column is the number of stars (1 through 5) assigned by the reviewer to the business. (Higher stars is better.) In other words, it is the rating of the business by the person who wrote the review.\n",
    "- The **text** column is the text of the review.\n",
    "- The **cool** column is the number of \"cool\" votes this review received from other Yelp users. All reviews start with 0 \"cool\" votes, and there is no limit to how many \"cool\" votes a review can receive. In other words, it is a rating of the review itself, not a rating of the business.\n",
    "- The **useful** and **funny** columns are similar to the **cool** column.\n",
    "\n",
    "**Goal:** Predict the star rating of a review using **only** the review text. (We will not be using the other columns.)\n",
    "\n",
    "**Tip:** After each task, I recommend that you check the shape and the contents of your objects, to confirm that they match your expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Read **`yelp.csv`** into a Pandas DataFrame and examine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use print only as a function\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('../data/yelp.csv')\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yelp_pred = data_df[['stars','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                               text\n",
       "0      5  My wife took me here on my birthday for breakf...\n",
       "1      5  I have no idea why some people give bad review...\n",
       "2      4  love the gyro plate. Rice is so good and I als...\n",
       "3      5  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...\n",
       "4      5  General Manager Scott Petello is a good egg!!!..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (Alternative)\n",
    "\n",
    "Ignore the **`yelp.csv`** file, and instead construct this DataFrame manually using **`yelp.json`**. This involves reading the file into Python, decoding the JSON, converting it to a DataFrame, and adding individual columns for each of the vote types.\n",
    "\n",
    "**Note:** This may be a challenging task, so I recommend skipping it unless you are fluent with Python and Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# read file as json, come back to later\n",
    "#with open('../data/yelp.json', 'rb') as f:\n",
    "    #data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data = map(lambda x: x.rstrip(), data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Create a new DataFrame that only contains the **5-star** and **1-star** reviews.\n",
    "\n",
    "- **Hint:** You will need to filter the DataFrame using an OR condition. [Working with DataFrames](http://www.gregreda.com/2013/10/26/working-with-pandas-dataframes/) has an example of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yelp1_5 = yelp_pred[(yelp_pred.stars == 5) | (yelp_pred.stars == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(yelp1_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   stars                                               text\n",
      "0      5  My wife took me here on my birthday for breakf...\n",
      "1      5  I have no idea why some people give bad review...\n",
      "3      5  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...\n",
      "4      5  General Manager Scott Petello is a good egg!!!...\n",
      "6      5  Drop what you're doing and drive here. After I...\n"
     ]
    }
   ],
   "source": [
    "print(yelp1_5.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4086.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.266765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.547868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             stars\n",
       "count  4086.000000\n",
       "mean      4.266765\n",
       "std       1.547868\n",
       "min       1.000000\n",
       "25%       5.000000\n",
       "50%       5.000000\n",
       "75%       5.000000\n",
       "max       5.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp1_5.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4086, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp1_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    3337\n",
       "1     749\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sms.label.value_counts()\n",
    "yelp1_5.stars.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Define X and y from the new DataFrame, and then split X and y into training and testing sets, using the **review text** as the only feature and the **star rating** as the response.\n",
    "\n",
    "- **Hint:** Keep in mind that X should be a Pandas Series (not a DataFrame), since we will pass it to CountVectorizer in the task that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4086,)\n",
      "(4086,)\n"
     ]
    }
   ],
   "source": [
    "# test using both types of subsetting - either seems to work\n",
    "X = yelp1_5.text\n",
    "y = yelp1_5.stars\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     My wife took me here on my birthday for breakf...\n",
       "1     I have no idea why some people give bad review...\n",
       "3     Rosie, Dakota, and I LOVE Chaparral Dog Park!!...\n",
       "4     General Manager Scott Petello is a good egg!!!...\n",
       "6     Drop what you're doing and drive here. After I...\n",
       "9     Nobuo shows his unique talents with everything...\n",
       "10    The oldish man who owns the store is as sweet ...\n",
       "11    Wonderful Vietnamese sandwich shoppe. Their ba...\n",
       "12    They have a limited time thing going on right ...\n",
       "17    okay this is the best place EVER! i grew up sh...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                        # WHY IS INDEX MISSING NUMBERS??? QUESTION FOR KEVIN...\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     5\n",
       "1     5\n",
       "3     5\n",
       "4     5\n",
       "6     5\n",
       "9     5\n",
       "10    5\n",
       "11    5\n",
       "12    5\n",
       "17    5\n",
       "21    5\n",
       "22    5\n",
       "23    1\n",
       "24    5\n",
       "26    5\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3064,)\n",
      "(1022,)\n",
      "(3064,)\n",
      "(1022,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "Use CountVectorizer to create **document-term matrices** from X_train and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import and instantiate CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3064x16825 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 237720 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform give you a \"document term matrix\" \"dtm\" - stored as a sparse matrix\n",
    "# documents are the rows, terms are the features. hence \"Document x Term x Matrix\"\n",
    "\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "\n",
    "# transform does the count. so it's counted when you transform it. That's why you can do \"fit\" for X_Train and then\n",
    "# And THEN transform.  But for y_train, we only transform. So it doesn't \"fit\" -- meaning find the relationship between\n",
    "# the features (term) and the rows (document) like fit does. It just counts - and specifically it ONLY counts the words\n",
    "# that were in X \"fit\". NOT new words.\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3064x16825 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 237720 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternative: combine fit and transform into a single step    THIS IS BETTER. USE THIS!!!\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '00a',\n",
       " '00am',\n",
       " '00pm',\n",
       " '01',\n",
       " '02',\n",
       " '03',\n",
       " '03342',\n",
       " '04',\n",
       " '05',\n",
       " '06',\n",
       " '07',\n",
       " '09',\n",
       " '0buxoc0crqjpvkezo3bqog',\n",
       " '0l',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '1000x',\n",
       " '1001',\n",
       " '100th',\n",
       " '101',\n",
       " '102',\n",
       " '105',\n",
       " '1070',\n",
       " '108',\n",
       " '10am',\n",
       " '10ish',\n",
       " '10min',\n",
       " '10mins',\n",
       " '10minutes',\n",
       " '10pm',\n",
       " '10th',\n",
       " '10x',\n",
       " '11',\n",
       " '110',\n",
       " '1100',\n",
       " '111',\n",
       " '111th',\n",
       " '112',\n",
       " '115th',\n",
       " '118',\n",
       " '11a',\n",
       " '11am',\n",
       " '11p',\n",
       " '11pm',\n",
       " '12',\n",
       " '120',\n",
       " '128i',\n",
       " '129',\n",
       " '12am',\n",
       " '12oz',\n",
       " '12pm',\n",
       " '12th',\n",
       " '13',\n",
       " '14',\n",
       " '140',\n",
       " '147',\n",
       " '14lbs',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '150mm',\n",
       " '15am',\n",
       " '15mins',\n",
       " '15pm',\n",
       " '15th',\n",
       " '16',\n",
       " '160',\n",
       " '165',\n",
       " '169',\n",
       " '16th',\n",
       " '17',\n",
       " '17p',\n",
       " '18',\n",
       " '180',\n",
       " '18th',\n",
       " '19',\n",
       " '1900',\n",
       " '1913',\n",
       " '1928',\n",
       " '1929',\n",
       " '1930s',\n",
       " '1940',\n",
       " '1952',\n",
       " '1955',\n",
       " '1956',\n",
       " '1960',\n",
       " '1961',\n",
       " '1969',\n",
       " '1970',\n",
       " '1980',\n",
       " '1980s',\n",
       " '1987',\n",
       " '1990s',\n",
       " '1992',\n",
       " '1995',\n",
       " '1996',\n",
       " '1998',\n",
       " '1999',\n",
       " '19th',\n",
       " '1cent',\n",
       " '1k',\n",
       " '1p',\n",
       " '1pm',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '2002',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '2008',\n",
       " '2009',\n",
       " '200lbs',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '202',\n",
       " '20mbs',\n",
       " '20miles',\n",
       " '20min',\n",
       " '20pm',\n",
       " '20s',\n",
       " '20th',\n",
       " '20x',\n",
       " '21',\n",
       " '22',\n",
       " '220',\n",
       " '2240',\n",
       " '22oz',\n",
       " '23',\n",
       " '24',\n",
       " '24hrs',\n",
       " '24st',\n",
       " '24th',\n",
       " '25',\n",
       " '250',\n",
       " '25b',\n",
       " '25min',\n",
       " '25th',\n",
       " '26',\n",
       " '260',\n",
       " '2600',\n",
       " '2608',\n",
       " '2669',\n",
       " '26th',\n",
       " '27',\n",
       " '272',\n",
       " '28',\n",
       " '29',\n",
       " '29th',\n",
       " '2am',\n",
       " '2mbps',\n",
       " '2nd',\n",
       " '2pm',\n",
       " '2rd',\n",
       " '2wice',\n",
       " '2x',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '30am',\n",
       " '30p',\n",
       " '30pm',\n",
       " '30th',\n",
       " '31',\n",
       " '311',\n",
       " '312',\n",
       " '32',\n",
       " '33',\n",
       " '33rd',\n",
       " '34',\n",
       " '34th',\n",
       " '35',\n",
       " '350ib',\n",
       " '35c',\n",
       " '35th',\n",
       " '36',\n",
       " '37',\n",
       " '370',\n",
       " '38',\n",
       " '38th',\n",
       " '39',\n",
       " '3am',\n",
       " '3d',\n",
       " '3g',\n",
       " '3k',\n",
       " '3lbs',\n",
       " '3n9u549zse8up',\n",
       " '3p',\n",
       " '3pm',\n",
       " '3rd',\n",
       " '3x',\n",
       " '40',\n",
       " '400',\n",
       " '4000',\n",
       " '40lm',\n",
       " '40min',\n",
       " '40th',\n",
       " '41',\n",
       " '411',\n",
       " '4113416766',\n",
       " '42',\n",
       " '420',\n",
       " '43',\n",
       " '44',\n",
       " '4458',\n",
       " '44th',\n",
       " '45',\n",
       " '453990',\n",
       " '45min',\n",
       " '45pm',\n",
       " '46',\n",
       " '475',\n",
       " '48',\n",
       " '480',\n",
       " '48th',\n",
       " '49',\n",
       " '490',\n",
       " '4b',\n",
       " '4hr',\n",
       " '4pm',\n",
       " '4th',\n",
       " '50',\n",
       " '500',\n",
       " '50cents',\n",
       " '50lm',\n",
       " '50s',\n",
       " '51',\n",
       " '51pm',\n",
       " '52',\n",
       " '5231',\n",
       " '53',\n",
       " '53pm',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '59',\n",
       " '59th',\n",
       " '5k',\n",
       " '5min',\n",
       " '5p',\n",
       " '5pm',\n",
       " '5stars',\n",
       " '5th',\n",
       " '60',\n",
       " '600',\n",
       " '602',\n",
       " '61',\n",
       " '61st',\n",
       " '62010',\n",
       " '623',\n",
       " '63',\n",
       " '64',\n",
       " '64th',\n",
       " '65',\n",
       " '66',\n",
       " '67',\n",
       " '68',\n",
       " '680',\n",
       " '69',\n",
       " '6am',\n",
       " '6p',\n",
       " '6pm',\n",
       " '6th',\n",
       " '70',\n",
       " '700',\n",
       " '70s',\n",
       " '70th',\n",
       " '71',\n",
       " '71st',\n",
       " '75',\n",
       " '750',\n",
       " '755891987',\n",
       " '76',\n",
       " '79',\n",
       " '7am',\n",
       " '7pm',\n",
       " '7th',\n",
       " '80',\n",
       " '800',\n",
       " '8000hp',\n",
       " '80s',\n",
       " '81',\n",
       " '83',\n",
       " '832',\n",
       " '83rd',\n",
       " '85',\n",
       " '85154658',\n",
       " '86',\n",
       " '88',\n",
       " '89',\n",
       " '8am',\n",
       " '8pm',\n",
       " '8th',\n",
       " '8v',\n",
       " '8yo',\n",
       " '90',\n",
       " '90s',\n",
       " '91',\n",
       " '911',\n",
       " '945am',\n",
       " '95',\n",
       " '96',\n",
       " '977',\n",
       " '98',\n",
       " '99',\n",
       " '9999',\n",
       " '99cent',\n",
       " '9oz',\n",
       " '9p',\n",
       " '9pm',\n",
       " '9year',\n",
       " '9yo',\n",
       " '______',\n",
       " '_______________',\n",
       " '_c',\n",
       " '_gyib8ea4hdfylss17zc_g',\n",
       " 'a1',\n",
       " 'aa',\n",
       " 'aaa',\n",
       " 'aaaamazing',\n",
       " 'aaammmazzing',\n",
       " 'aaron',\n",
       " 'ab',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abba',\n",
       " 'abbreviate',\n",
       " 'abbreviated',\n",
       " 'abby',\n",
       " 'abc',\n",
       " 'abdomen',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'abodoba',\n",
       " 'abound',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abrasion',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'absent',\n",
       " 'absinthe',\n",
       " 'absoloutely',\n",
       " 'absolut',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutley',\n",
       " 'absolutly',\n",
       " 'abstained',\n",
       " 'absurd',\n",
       " 'abuelo',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abusive',\n",
       " 'ac',\n",
       " 'academy',\n",
       " 'acapulco',\n",
       " 'accent',\n",
       " 'accented',\n",
       " 'accents',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'accepted',\n",
       " 'access',\n",
       " 'accessed',\n",
       " 'accessible',\n",
       " 'accessories',\n",
       " 'accessorize',\n",
       " 'accessory',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accolades',\n",
       " 'accommodate',\n",
       " 'accommodated',\n",
       " 'accommodates',\n",
       " 'accommodating',\n",
       " 'accommodations',\n",
       " 'accomodate',\n",
       " 'accomodating',\n",
       " 'accompanied',\n",
       " 'accompanies',\n",
       " 'accompaniment',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishment',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accounts',\n",
       " 'accoutrement',\n",
       " 'accredited',\n",
       " 'accross',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusation',\n",
       " 'accustom',\n",
       " 'accustomed',\n",
       " 'accutemp',\n",
       " 'ace',\n",
       " 'ache',\n",
       " 'aches',\n",
       " 'achieve',\n",
       " 'achievement',\n",
       " 'acid',\n",
       " 'acidic',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledgement',\n",
       " 'acknowledging',\n",
       " 'ackward',\n",
       " 'acne',\n",
       " 'acoustic',\n",
       " 'acoustics',\n",
       " 'acquaintance',\n",
       " 'acres',\n",
       " 'acrid',\n",
       " 'acrimonious',\n",
       " 'across',\n",
       " 'acrylics',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'activation',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activism',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'actualy',\n",
       " 'actully',\n",
       " 'acute',\n",
       " 'acy',\n",
       " 'ad',\n",
       " 'adage',\n",
       " 'adam',\n",
       " 'adamant',\n",
       " 'adams',\n",
       " 'adapter',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addendum',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addicting',\n",
       " 'addictingly',\n",
       " 'addiction',\n",
       " 'addictionovercome',\n",
       " 'addictive',\n",
       " 'addicts',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additions',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'ade',\n",
       " 'adelman',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adios',\n",
       " 'adjacent',\n",
       " 'adjoining',\n",
       " 'adjust',\n",
       " 'adjusted',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'administrative',\n",
       " 'admire',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'admonishment',\n",
       " 'adobada',\n",
       " 'adobe',\n",
       " 'adobo',\n",
       " 'adolescence',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adoption',\n",
       " 'adoptions',\n",
       " 'adorable',\n",
       " 'adore',\n",
       " 'adorning',\n",
       " 'adovada',\n",
       " 'adquate',\n",
       " 'adrienne',\n",
       " 'ads',\n",
       " 'adult',\n",
       " 'adulthood',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantages',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'adventurous',\n",
       " 'adverse',\n",
       " 'adversity',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advertising',\n",
       " 'adverts',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'advising',\n",
       " 'advisor',\n",
       " 'advocate',\n",
       " 'advocated',\n",
       " 'aeg',\n",
       " 'aerators',\n",
       " 'aerobic',\n",
       " 'aerobics',\n",
       " 'aeropress',\n",
       " 'aesthetically',\n",
       " 'aesthetics',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affects',\n",
       " 'afficianados',\n",
       " 'affiliated',\n",
       " 'affiliation',\n",
       " 'affluent',\n",
       " 'afforadable',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'aficionado',\n",
       " 'aficionados',\n",
       " 'afloat',\n",
       " 'aforementioned',\n",
       " 'afoul',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'after',\n",
       " 'afterall',\n",
       " 'afterdark',\n",
       " 'afterglow',\n",
       " 'afternoon',\n",
       " 'afternoons',\n",
       " 'aftertaste',\n",
       " 'afterthought',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'agape',\n",
       " 'agave',\n",
       " 'agaves',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agency',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'aggressive',\n",
       " 'aging',\n",
       " 'agitated',\n",
       " 'ago',\n",
       " 'agonizing',\n",
       " 'agree',\n",
       " 'agreeable',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreement',\n",
       " 'agrees',\n",
       " 'agua',\n",
       " 'aguas',\n",
       " 'agwa',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahem',\n",
       " 'ahh',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'ahhhhh',\n",
       " 'ahi',\n",
       " 'ahold',\n",
       " 'ahwatukee',\n",
       " 'aid',\n",
       " 'aiello',\n",
       " 'aiko',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aimlessly',\n",
       " 'aims',\n",
       " 'ain',\n",
       " 'aint',\n",
       " 'aioli',\n",
       " 'aiptasia',\n",
       " 'air',\n",
       " 'airconditioned',\n",
       " 'airfair',\n",
       " 'airfare',\n",
       " 'airline',\n",
       " 'airlines',\n",
       " 'airpark',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'airports',\n",
       " 'airwarys',\n",
       " 'airways',\n",
       " 'airy',\n",
       " 'aisha',\n",
       " 'aisle',\n",
       " 'aisles',\n",
       " 'aj',\n",
       " 'aji',\n",
       " 'ajo',\n",
       " 'ajos',\n",
       " 'ajs',\n",
       " 'ajvar',\n",
       " 'aka',\n",
       " 'aki',\n",
       " 'aknowledging',\n",
       " 'akor',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alabama',\n",
       " 'alain',\n",
       " 'alameda',\n",
       " 'alan',\n",
       " 'alarmed',\n",
       " 'alas',\n",
       " 'alaskan',\n",
       " 'alaus',\n",
       " 'albacore',\n",
       " 'albeit',\n",
       " 'alber',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'alcohol',\n",
       " 'alcoholic',\n",
       " 'aldo',\n",
       " 'ale',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alexandra',\n",
       " 'alfalfa',\n",
       " 'alfonso',\n",
       " 'alfred',\n",
       " 'alfredo',\n",
       " 'algae',\n",
       " 'ali',\n",
       " 'alice',\n",
       " 'alicia',\n",
       " 'aliens',\n",
       " 'alike',\n",
       " 'alittle',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'alla',\n",
       " 'allayed',\n",
       " 'alleged',\n",
       " 'allegiant',\n",
       " 'allen',\n",
       " 'allende',\n",
       " 'allergen',\n",
       " 'allergic',\n",
       " 'allergies',\n",
       " 'allergy',\n",
       " 'alleviated',\n",
       " 'alley',\n",
       " 'alligator',\n",
       " 'allocating',\n",
       " 'allot',\n",
       " 'alloted',\n",
       " 'allotted',\n",
       " 'allow',\n",
       " 'allowable',\n",
       " 'allowance',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'allure',\n",
       " 'almond',\n",
       " 'almonds',\n",
       " 'almost',\n",
       " 'aloe',\n",
       " 'alofts',\n",
       " 'aloha',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alongside',\n",
       " 'alons',\n",
       " 'aloo',\n",
       " 'aloof',\n",
       " 'alot',\n",
       " 'aloud',\n",
       " 'alp',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'alteration',\n",
       " 'alterations',\n",
       " 'altercation',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'alternately',\n",
       " 'alternative',\n",
       " 'alternatively',\n",
       " 'alternatives',\n",
       " 'although',\n",
       " 'altic',\n",
       " 'aluminum',\n",
       " 'alway',\n",
       " 'always',\n",
       " 'am',\n",
       " 'ama',\n",
       " 'amaaaaazing',\n",
       " 'amaazing',\n",
       " 'amados',\n",
       " 'amalfi',\n",
       " 'amanda',\n",
       " 'amaretti',\n",
       " 'amaretto',\n",
       " 'amarillo',\n",
       " 'amaro',\n",
       " 'amateur',\n",
       " 'amaze',\n",
       " 'amazed',\n",
       " 'amazement',\n",
       " 'amazes',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazingness',\n",
       " 'amazon',\n",
       " 'amazzzzzzing',\n",
       " 'ambassador',\n",
       " 'amber',\n",
       " 'ambiance',\n",
       " 'ambience',\n",
       " 'ambient',\n",
       " 'ambrosia',\n",
       " 'amc',\n",
       " 'amenable',\n",
       " 'amendment',\n",
       " 'amenities',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americana',\n",
       " 'americanized',\n",
       " 'americano',\n",
       " 'americanos',\n",
       " 'americans',\n",
       " 'ami',\n",
       " 'amicable',\n",
       " 'amidst',\n",
       " 'amin',\n",
       " 'amish',\n",
       " 'ammo',\n",
       " 'amomi',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amore',\n",
       " 'amount',\n",
       " 'amounted',\n",
       " 'amounts',\n",
       " 'amp',\n",
       " 'amphitheatre',\n",
       " 'ample',\n",
       " 'ampm',\n",
       " 'amtrack',\n",
       " 'amuse',\n",
       " 'amused',\n",
       " 'amusement',\n",
       " 'amusing',\n",
       " 'amy',\n",
       " 'an',\n",
       " 'anal',\n",
       " 'analysis',\n",
       " 'ancho',\n",
       " 'anchor',\n",
       " 'anchors',\n",
       " 'anchovies',\n",
       " 'anchovy',\n",
       " 'and',\n",
       " 'andiamo',\n",
       " 'andouille',\n",
       " 'andrea',\n",
       " 'andrew',\n",
       " 'andy',\n",
       " 'anecdotes',\n",
       " 'anemic',\n",
       " 'anesthetic',\n",
       " 'anew',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angeles',\n",
       " 'angelic',\n",
       " 'angello',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'anglaise',\n",
       " 'angle',\n",
       " 'angler',\n",
       " 'angles',\n",
       " 'angry',\n",
       " 'angst',\n",
       " 'anibal',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'animated',\n",
       " 'animatronics',\n",
       " 'anise',\n",
       " 'aniston',\n",
       " 'ankle',\n",
       " 'ankles',\n",
       " 'ann',\n",
       " 'anne',\n",
       " 'annie',\n",
       " 'annihilator',\n",
       " 'anniversary',\n",
       " 'announced',\n",
       " 'annoy',\n",
       " 'annoyance',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annual',\n",
       " 'anomaly',\n",
       " 'anonymous',\n",
       " 'another',\n",
       " 'ans',\n",
       " 'ansel',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'ant',\n",
       " 'anthem',\n",
       " 'anthony',\n",
       " 'anti',\n",
       " 'anticipate',\n",
       " 'anticipated',\n",
       " 'anticipating',\n",
       " 'anticipation',\n",
       " 'antipasti',\n",
       " 'antipasto',\n",
       " 'antique',\n",
       " 'antiques',\n",
       " 'antiquing',\n",
       " 'antiseptic',\n",
       " 'antithesis',\n",
       " 'antler',\n",
       " 'antonio',\n",
       " 'antono',\n",
       " 'ants',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'anxiously',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyday',\n",
       " 'anyhoo',\n",
       " 'anyhow',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anyplace',\n",
       " 'anything',\n",
       " 'anythings',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'anywho',\n",
       " 'ao',\n",
       " 'ap',\n",
       " 'apache',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apartments',\n",
       " 'ape',\n",
       " 'apiece',\n",
       " 'apologetic',\n",
       " 'apologetically',\n",
       " 'apologists',\n",
       " 'apologize',\n",
       " 'apologized',\n",
       " 'apologizes',\n",
       " 'apologizing',\n",
       " 'apology',\n",
       " 'apostles',\n",
       " 'apothecary',\n",
       " 'apothic',\n",
       " 'app',\n",
       " 'appalachians',\n",
       " 'appaled',\n",
       " 'appalled',\n",
       " 'appalling',\n",
       " 'apparantly',\n",
       " 'apparel',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appauling',\n",
       " 'appeal',\n",
       " 'appealed',\n",
       " 'appealing',\n",
       " 'appeals',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appearances',\n",
       " 'appeared',\n",
       " 'appears',\n",
       " 'appeasing',\n",
       " 'appertizer',\n",
       " 'appetit',\n",
       " 'appetite',\n",
       " 'appetito',\n",
       " 'appetizaer',\n",
       " 'appetizer',\n",
       " 'appetizers',\n",
       " 'appetizing',\n",
       " 'applaud',\n",
       " 'apple',\n",
       " 'applebee',\n",
       " 'applebees',\n",
       " 'apples',\n",
       " 'appletini',\n",
       " 'appletinis',\n",
       " 'appliances',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appoinmtnt',\n",
       " 'appointed',\n",
       " 'appointment',\n",
       " 'appointments',\n",
       " 'appologized',\n",
       " 'appraisal',\n",
       " 'appraisals',\n",
       " 'appraiser',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciates',\n",
       " 'appreciation',\n",
       " 'appreciative',\n",
       " 'apprehensive',\n",
       " 'appreicate',\n",
       " 'approach',\n",
       " 'approachable',\n",
       " 'approached',\n",
       " 'approaches',\n",
       " 'approaching',\n",
       " 'appropriate',\n",
       " 'appropriately',\n",
       " 'approx',\n",
       " 'approximate',\n",
       " 'approximately',\n",
       " 'apps',\n",
       " 'appt',\n",
       " 'appys',\n",
       " 'apricot',\n",
       " 'april',\n",
       " 'apron',\n",
       " 'apt',\n",
       " 'aqua',\n",
       " 'aquarium',\n",
       " 'aquiring',\n",
       " 'ar',\n",
       " 'arabic',\n",
       " 'arai',\n",
       " 'arbol',\n",
       " 'arboreal',\n",
       " 'arborio',\n",
       " 'arcade',\n",
       " 'arcadia',\n",
       " 'arcane',\n",
       " 'arches',\n",
       " 'architect',\n",
       " 'architecture',\n",
       " ...]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1022x16825 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 77006 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                            #QUESTION FOR KEVIN & ALEX - \n",
    "#                             how does vect.get_feature_names() know to get feature names from X_train\n",
    "#                             without passing X_train as a parameter????\n",
    "\n",
    "# vect.get_feature_names essentially tokenizes \n",
    "X_train_tokens = vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '00pm', '02', '04', '05', '06', '10', '100', '1000', '100s', '101', '1030', '105', '108', '109', '10am', '10pm', '10th', '10yo', '11', '110', '115', '116', '11am', '12', '120', '13', '1300', '13331', '13th', '14', '15', '150', '157', '16', '16th', '17', '175', '17th', '18', '1800', '1895', '19', '1968', '1978', '1980s', '1990', '1997', '19th']\n"
     ]
    }
   ],
   "source": [
    "# examine the first 50 tokens\n",
    "print(X_train_tokens[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['york', 'yorker', 'yorkers', 'you', 'youd', 'young', 'younger', 'youngest', 'youngggg', 'youngtown', 'your', 'yours', 'yourself', 'youth', 'yr', 'yuck', 'yum', 'yumm', 'yumminess', 'yummmayyyy', 'yummmmm', 'yummmmmmmm', 'yummo', 'yummy', 'yup', 'yur', 'yuri', 'yyyeeaahhhh', 'zen', 'zero', 'zesty', 'zichini', 'zillion', 'zin', 'zinburger', 'zinc', 'zip', 'ziploc', 'zipps', 'zoe', 'zone', 'zoners', 'zones', 'zoo', 'zoom', 'zucchini', 'zuccini', 'zupas', 'zuzu', 'zuzus']\n"
     ]
    }
   ],
   "source": [
    "# examine the last 50 tokens\n",
    "print(X_train_tokens[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3064, 16825)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([65,  9,  1, ...,  1,  1,  1], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# count how many times EACH token appears across ALL messages in X_train_dtm\n",
    "X_train_counts = np.sum(X_train_dtm.toarray(), axis=0)\n",
    "X_train_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "Use Multinomial Naive Bayes to **predict the star rating** for the reviews in the testing set, and then **calculate the accuracy** and **print the confusion matrix**.\n",
    "\n",
    "- **Hint:** [Evaluating a classification model](https://github.com/justmarkham/scikit-learn-videos/blob/master/09_classification_metrics.ipynb) explains how to interpret both classification accuracy and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a Naive Bayes model using X_train_dtm\n",
    "nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 26.,   4.,   1., ...,   0.,   0.,   0.],\n",
       "       [ 39.,   5.,   0., ...,   1.,   1.,   1.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick aside: Naive Bayes will count the features in each class for you!\n",
    "nb.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91878669275929548"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[126,  58],\n",
       "       [ 25, 813]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 (Challenge)\n",
    "\n",
    "Calculate the **null accuracy**, which is the classification accuracy that could be achieved by always predicting the most frequent class.\n",
    "\n",
    "- **Hint:** [Evaluating a classification model](https://github.com/justmarkham/scikit-learn-videos/blob/master/09_classification_metrics.ipynb) explains null accuracy and demonstrates two ways to calculate it, though only one of those ways will work in this case. Alternatively, you can come up with your own method to calculate null accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7 (Challenge)\n",
    "\n",
    "Calculate which 5 tokens are the most predictive of **5-star reviews**, and which 5 tokens are the most predictive of **1-star reviews**.\n",
    "\n",
    "- **Hint:** Use the `feature_count_` attribute from the Naive Bayes model object as a shortcut, so that you don't have to do any NumPy math."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8 (Challenge)\n",
    "\n",
    "Browse through the review text of some of the **false positives** and **false negatives**. Based on your knowledge of how Naive Bayes works, do you have any ideas about why the model is incorrectly classifying these reviews?\n",
    "\n",
    "- **Hint:** [Evaluating a classification model](https://github.com/justmarkham/scikit-learn-videos/blob/master/09_classification_metrics.ipynb) explains the definitions of \"false positives\" and \"false negatives\".\n",
    "- **Hint:** Think about what a false positive means in this context, and what a false negative means in this context. What has scikit-learn defined as the \"positive class\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9 (Challenge)\n",
    "\n",
    "Up to this point, we have framed this as a **binary classification problem** by only considering the 5-star and 1-star reviews. Now, let's repeat the model building process using all reviews, which makes this a **5-class classification problem**.\n",
    "\n",
    "Here are the steps:\n",
    "\n",
    "- Define X and y using the original DataFrame. (y should contain 5 different classes.)\n",
    "- Split X and y into training and testing sets.\n",
    "- Create document-term matrices using CountVectorizer.\n",
    "- Calculate the testing accuracy of a Multinomial Naive Bayes model.\n",
    "- Compare the testing accuracy with the null accuracy.\n",
    "- Print the confusion matrix.\n",
    "- Comment on the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
